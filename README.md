
# ğŸ§ª Tarea 3: ComunicaciÃ³n colectiva y mediciÃ³n de latencia en MPI

Este repositorio contiene la soluciÃ³n a la Tarea 3 del curso de **ComputaciÃ³n Paralela y Distribuida**, utilizando `mpi4py` y ejecutable en **Google Colab**.

## ğŸ‘¨â€ğŸ« Profesor
Johansell Villalobos Cubillo

## ğŸ§‘â€ğŸ’» Autor
Daniel Matarrita

---

## ğŸ“ Estructura del repositorio

```
Tarea3_MPI/
â”œâ”€â”€ parteA_estadisticas_mpi.py     # Parte A: Operaciones colectivas
â”œâ”€â”€ parteB_latencia_mpi.py         # Parte B: MediciÃ³n de latencia
â”œâ”€â”€ Tarea3_MPI_Explicada.ipynb     # Notebook completo para Colab
â””â”€â”€ README.md                      # Instrucciones y documentaciÃ³n
```

---

## ğŸš€ Requisitos

Este proyecto se puede ejecutar en:

- Google Colab
- Entornos Linux con MPI y Python 3

Dependencias:
```bash
sudo apt-get install libopenmpi-dev openmpi-bin
pip install mpi4py
```

---

## â–¶ï¸ EjecuciÃ³n

### Parte A â€“ EstadÃ­sticas con MPI

Distribuye un arreglo entre procesos y calcula el mÃ­nimo, mÃ¡ximo y promedio global usando:

- `MPI_Bcast`
- `MPI_Scatter`
- `MPI_Reduce`

```bash
mpirun -np 4 python3 parteA_estadisticas_mpi.py 1000000
```

### Parte B â€“ MediciÃ³n de Latencia Punto a Punto

Mide el tiempo que toma enviar y recibir mensajes pequeÃ±os entre dos procesos.

```bash
mpirun -np 2 python3 parteB_latencia_mpi.py
```

---

## ğŸ“ˆ Resultados esperados

### Parte A:
```
Min global: 0.0003
Max global: 99.9984
Promedio global: 50.1021
```

### Parte B:
```
Mensaje de 1 byte transmitido 10000 veces.
Latencia promedio (ida y vuelta): 3.2 Âµs
Latencia estimada unidireccional: 1.6 Âµs
```

---

## ğŸ“Œ Notas

- AsegÃºrate de que el valor de `N` en la parte A sea divisible entre el nÃºmero de procesos.
- Puedes editar los scripts para probar diferentes tamaÃ±os de mensaje o nÃºmero de iteraciones.

---

## ğŸ“„ Informe

El informe se encuentra integrado en el archivo `.ipynb` con explicaciones de cada paso y anÃ¡lisis de resultados.
