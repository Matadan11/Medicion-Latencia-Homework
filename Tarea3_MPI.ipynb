{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matadan11/Medicion-Latencia-Homework/blob/main/Tarea3_MPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPjqupmQYKRK"
      },
      "source": [
        "# üß™ Tarea 3: Comunicaci√≥n colectiva y medici√≥n de latencia con MPI en Python (Colab)\n",
        "\n",
        "**Autor:** Daniel Matarrita  \n",
        "**Curso:** Computaci√≥n Paralela y Distribuida  \n",
        "**Profesor:** Johansell Villalobos  \n",
        "\n",
        "Este notebook implementa y explica paso a paso las dos partes de la Tarea 3:\n",
        "- Parte A: Operaciones colectivas en MPI (`Bcast`, `Scatter`, `Reduce`)\n",
        "- Parte B: Medici√≥n de latencia punto a punto (`Send`, `Recv`)\n",
        "\n",
        "> ‚ö†Ô∏è Este notebook est√° pensado para ejecutarse en **Google Colab**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya1zNxnNYKRR",
        "outputId": "3b6f4f00-9a75-4208-9fe5-fbc13d232506"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ],
      "source": [
        "# ‚úÖ Paso 1: Instalaci√≥n de dependencias necesarias en Colab\n",
        "!apt-get update > /dev/null\n",
        "!apt-get install -y libopenmpi-dev openmpi-bin > /dev/null\n",
        "!pip install mpi4py > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtYuCVd-YKRT"
      },
      "source": [
        "## üß© Parte A: Estad√≠sticas globales con operaciones colectivas\n",
        "\n",
        "En esta parte usaremos `MPI_Bcast`, `MPI_Scatter`, y `MPI_Reduce` para distribuir un arreglo de n√∫meros y calcular el m√≠nimo, m√°ximo y promedio global."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi8B6thJYKRV",
        "outputId": "c6f844d1-df3d-4152-ebaf-57c75f2ef606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing parteA_estadisticas_mpi.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile parteA_estadisticas_mpi.py\n",
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.Get_rank()\n",
        "size = comm.Get_size()\n",
        "\n",
        "# Tama√±o del arreglo desde argumentos\n",
        "N = int(sys.argv[1]) if len(sys.argv) > 1 else 1000000\n",
        "\n",
        "if N % size != 0:\n",
        "    if rank == 0:\n",
        "        print(\"Error: N no divisible entre procesos\")\n",
        "    exit()\n",
        "\n",
        "sub_size = N // size\n",
        "data = None\n",
        "if rank == 0:\n",
        "    data = np.random.uniform(0, 100, N)\n",
        "\n",
        "sub_data = np.empty(sub_size, dtype='d')\n",
        "comm.Scatter(data, sub_data, root=0)\n",
        "\n",
        "local_min = np.min(sub_data)\n",
        "local_max = np.max(sub_data)\n",
        "local_sum = np.sum(sub_data)\n",
        "\n",
        "global_min = comm.reduce(local_min, op=MPI.MIN, root=0)\n",
        "global_max = comm.reduce(local_max, op=MPI.MAX, root=0)\n",
        "global_sum = comm.reduce(local_sum, op=MPI.SUM, root=0)\n",
        "\n",
        "if rank == 0:\n",
        "    print(f\"Min global: {global_min}\")\n",
        "    print(f\"Max global: {global_max}\")\n",
        "    print(f\"Promedio global: {global_sum / N}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9Mg-60wYKRW",
        "outputId": "2424b9fa-9d01-4755-c7b3-0b6c69c4b647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------\n",
            "mpirun has detected an attempt to run as root.\n",
            "\n",
            "Running as root is *strongly* discouraged as any mistake (e.g., in\n",
            "defining TMPDIR) or bug can result in catastrophic damage to the OS\n",
            "file system, leaving your system in an unusable state.\n",
            "\n",
            "We strongly suggest that you run mpirun as a non-root user.\n",
            "\n",
            "You can override this protection by adding the --allow-run-as-root option\n",
            "to the cmd line or by setting two environment variables in the following way:\n",
            "the variable OMPI_ALLOW_RUN_AS_ROOT=1 to indicate the desire to override this\n",
            "protection, and OMPI_ALLOW_RUN_AS_ROOT_CONFIRM=1 to confirm the choice and\n",
            "add one more layer of certainty that you want to do so.\n",
            "We reiterate our advice against doing so - please proceed at your own risk.\n",
            "--------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ‚ñ∂Ô∏è Ejecutar Parte A con 4 procesos\n",
        "!mpirun -np 4 python3 parteA_estadisticas_mpi.py 1000000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJAZRW4JYKRX"
      },
      "source": [
        "## üì° Parte B: Medici√≥n de latencia punto a punto\n",
        "\n",
        "Esta parte implementa la medici√≥n de latencia entre dos procesos usando `MPI_Send` y `MPI_Recv` de ida y vuelta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpDRepkYYKRY",
        "outputId": "6dc593f0-58c3-4626-e851-3ef6c71d28d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing parteB_latencia_mpi.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile parteB_latencia_mpi.py\n",
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.Get_rank()\n",
        "size = comm.Get_size()\n",
        "\n",
        "if size != 2:\n",
        "    if rank == 0:\n",
        "        print(\"Este programa requiere exactamente 2 procesos\")\n",
        "    exit()\n",
        "\n",
        "N = 10000\n",
        "msg = np.array([0], dtype='b')  # Mensaje de 1 byte\n",
        "\n",
        "if rank == 0:\n",
        "    start = MPI.Wtime()\n",
        "    for _ in range(N):\n",
        "        comm.Send([msg, MPI.BYTE], dest=1)\n",
        "        comm.Recv([msg, MPI.BYTE], source=1)\n",
        "    end = MPI.Wtime()\n",
        "    total_time = end - start\n",
        "    avg_latency = (total_time / N) * 1e6  # microsegundos\n",
        "    print(f\"Mensaje de 1 byte transmitido {N} veces.\")\n",
        "    print(f\"Latencia promedio (ida y vuelta): {avg_latency:.2f} ¬µs\")\n",
        "    print(f\"Latencia estimada unidireccional: {avg_latency/2:.2f} ¬µs\")\n",
        "\n",
        "elif rank == 1:\n",
        "    for _ in range(N):\n",
        "        comm.Recv([msg, MPI.BYTE], source=0)\n",
        "        comm.Send([msg, MPI.BYTE], dest=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWqrmMoiYKRZ",
        "outputId": "2395bf61-96f1-4cae-a09e-ea91701885a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------\n",
            "mpirun has detected an attempt to run as root.\n",
            "\n",
            "Running as root is *strongly* discouraged as any mistake (e.g., in\n",
            "defining TMPDIR) or bug can result in catastrophic damage to the OS\n",
            "file system, leaving your system in an unusable state.\n",
            "\n",
            "We strongly suggest that you run mpirun as a non-root user.\n",
            "\n",
            "You can override this protection by adding the --allow-run-as-root option\n",
            "to the cmd line or by setting two environment variables in the following way:\n",
            "the variable OMPI_ALLOW_RUN_AS_ROOT=1 to indicate the desire to override this\n",
            "protection, and OMPI_ALLOW_RUN_AS_ROOT_CONFIRM=1 to confirm the choice and\n",
            "add one more layer of certainty that you want to do so.\n",
            "We reiterate our advice against doing so - please proceed at your own risk.\n",
            "--------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ‚ñ∂Ô∏è Ejecutar Parte B con 2 procesos\n",
        "!mpirun -np 2 python3 parteB_latencia_mpi.py"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}